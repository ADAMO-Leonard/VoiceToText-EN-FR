{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "743b0b26-e766-462b-91ef-6596a6b30797",
   "metadata": {},
   "source": [
    "**Detection de la voix:**\n",
    "\n",
    "**Etape 1:** initialisation des librairies\n",
    "\n",
    "**Etape 2:** initialisation du modele et audio\n",
    "\n",
    "**Etape 3:** Recuperation du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5de4028-0da8-43ba-bf34-b55e04bb1f99",
   "metadata": {},
   "source": [
    "**Etape 1:** initialisation des librairies\n",
    "\n",
    "Vous dever crée un environnement anaconda depuis anaconda prompt:\n",
    "\n",
    "*conda create -n test python=3.8*\n",
    "\n",
    "*conda activate test*\n",
    "\n",
    "installer les librairies\n",
    "\n",
    "*pip install pyaudio*\n",
    "\n",
    "*pip install vosk*\n",
    "\n",
    "*conda install jupyter*\n",
    "\n",
    "Ensuite vous devez telecharger le model [vosk-model-small-fr-0.22](https://alphacephei.com/vosk/models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c80a3946-fa3e-4e0d-bc1c-a53eec2b30d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importer les librairie \n",
    "import os\n",
    "import pyaudio #pip install pyaudio\n",
    "from vosk import Model, KaldiRecognizer   #pip install vosk\n",
    "import json #bibliotèque Json "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd74e13-a85d-47ba-9043-8a261ddedef7",
   "metadata": {},
   "source": [
    "**Etape 2:** initialisation du modele et audio\n",
    "\n",
    "mettre le modele télécharger dans le dossier de votre choix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe02b986-d926-497d-9ac9-5360e1bf7212",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\"C:/Users/leo/Documents/vosk-model-small-fr-0.22\") #Charger le modèle dans l'emplacement souhaité\n",
    "recognizer = KaldiRecognizer(model, 16000) #initialiser le modèle\n",
    "\n",
    "p = pyaudio.PyAudio() #initialise une instance pyaudio\n",
    "stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=8000, input_device_index=3) #defininis les parametre d'entrée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61a5d9a-eeb5-40ae-8553-2fc64bc5c878",
   "metadata": {},
   "source": [
    "**Etape 3:** Recuperation du texte\n",
    "\n",
    "Maintenant, nous regardons si du text est trouver et on stock la version définitif du texte obtenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b58950bb-e4fb-43b8-a8d8-b8f59028757d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultat obtenu: salut je m'appelle léo\n"
     ]
    }
   ],
   "source": [
    "texte = \"\"\n",
    "\n",
    "while texte == \"\":\n",
    "        data = stream.read(16000, exception_on_overflow=False)\n",
    "\n",
    "        if recognizer.AcceptWaveform(data):\n",
    "            texte=recognizer.Result()\n",
    "            texte = json.loads(texte)\n",
    "            texte = texte.get(\"text\", \"\")\n",
    "       \n",
    "print(\"resultat obtenu: \" + texte)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
